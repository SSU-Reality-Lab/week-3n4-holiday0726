{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XdhR8VklZ21m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import imageio.v2 as imageio\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXqbtIpld-2r"
      },
      "source": [
        "# Details of make_classification function\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIp73_Gkg3Wl"
      },
      "source": [
        "# 실습 1 : TPR과 FPR로 그려진 AUROC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5rphdrsfc8hl"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGg8buSnfKI8",
        "outputId": "b02d9a1c-d243-4103-f7eb-577f82ee4276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainy - class0:  253\n",
            "trainy - class1:  247\n",
            "----------------------\n",
            "testy - class0:  249\n",
            "testy - class1:  251\n",
            "============================\n",
            "Balanced Testing date\n",
            "testy - class0:  249\n",
            "testy - class1:  249\n"
          ]
        }
      ],
      "source": [
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=1000)\n",
        "\n",
        "print('trainy - class0: ', len(trainy)-trainy.sum())\n",
        "print('trainy - class1: ', trainy.sum())\n",
        "print('----------------------')\n",
        "print('testy - class0: ', len(testy)-testy.sum())\n",
        "print('testy - class1: ', testy.sum())\n",
        "print('============================')\n",
        "\n",
        "# make testing dataset balance\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "testX, testy = undersample.fit_resample(testX, testy)\n",
        "\n",
        "print('Balanced Testing date')\n",
        "print('testy - class0: ', len(testy)-testy.sum())\n",
        "print('testy - class1: ', testy.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "uacNKTAlgZ4u",
        "outputId": "117d7162-dbd1-4e4a-e991-77ac274b8db1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-6 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-6 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content {\n",
              "  display: none;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  overflow: visible;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-6 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-6 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-6 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".estimator-table summary {\n",
              "    padding: .5rem;\n",
              "    font-family: monospace;\n",
              "    cursor: pointer;\n",
              "}\n",
              "\n",
              ".estimator-table details[open] {\n",
              "    padding-left: 0.1rem;\n",
              "    padding-right: 0.1rem;\n",
              "    padding-bottom: 0.3rem;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table {\n",
              "    margin-left: auto !important;\n",
              "    margin-right: auto !important;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(odd) {\n",
              "    background-color: #fff;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(even) {\n",
              "    background-color: #f6f6f6;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:hover {\n",
              "    background-color: #e0e0e0;\n",
              "}\n",
              "\n",
              ".estimator-table table td {\n",
              "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
              "}\n",
              "\n",
              ".user-set td {\n",
              "    color:rgb(255, 94, 0);\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td.value pre {\n",
              "    color:rgb(255, 94, 0) !important;\n",
              "    background-color: transparent !important;\n",
              "}\n",
              "\n",
              ".default td {\n",
              "    color: black;\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td i,\n",
              ".default td i {\n",
              "    color: black;\n",
              "}\n",
              "\n",
              ".copy-paste-icon {\n",
              "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
              "    background-repeat: no-repeat;\n",
              "    background-size: 14px 14px;\n",
              "    background-position: 0;\n",
              "    display: inline-block;\n",
              "    width: 14px;\n",
              "    height: 14px;\n",
              "    cursor: pointer;\n",
              "}\n",
              "</style><body><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
              "        <div class=\"estimator-table\">\n",
              "            <details>\n",
              "                <summary>Parameters</summary>\n",
              "                <table class=\"parameters-table\">\n",
              "                  <tbody>\n",
              "                    \n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('penalty',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">penalty&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('dual',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">dual&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('tol',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">tol&nbsp;</td>\n",
              "            <td class=\"value\">0.0001</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('C',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">C&nbsp;</td>\n",
              "            <td class=\"value\">1.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('fit_intercept',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('intercept_scaling',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
              "            <td class=\"value\">1</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('class_weight',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">class_weight&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('random_state',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">random_state&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('solver',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">solver&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('max_iter',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">max_iter&nbsp;</td>\n",
              "            <td class=\"value\">100</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('multi_class',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">multi_class&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('verbose',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">verbose&nbsp;</td>\n",
              "            <td class=\"value\">0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('warm_start',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">warm_start&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('n_jobs',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">n_jobs&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('l1_ratio',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "                  </tbody>\n",
              "                </table>\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "</script></body>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "4xCG-HZTgpbD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nth 0:positive: 249 negative: 249\n",
            "---------------------------------------------\n",
            "nth 1:positive: 225 negative: 249\n",
            "---------------------------------------------\n",
            "nth 2:positive: 200 negative: 249\n",
            "---------------------------------------------\n",
            "nth 3:positive: 175 negative: 249\n",
            "---------------------------------------------\n",
            "nth 4:positive: 150 negative: 249\n",
            "---------------------------------------------\n",
            "nth 5:positive: 125 negative: 249\n",
            "---------------------------------------------\n",
            "nth 6:positive: 100 negative: 249\n",
            "---------------------------------------------\n",
            "nth 7:positive: 75 negative: 249\n",
            "---------------------------------------------\n",
            "nth 8:positive: 50 negative: 249\n",
            "---------------------------------------------\n",
            "nth 9:positive: 25 negative: 249\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'decreasing positive sample')"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# repeat with different skewness\n",
        "roc_list = []\n",
        "lr_acc = []\n",
        "k=1\n",
        "for i in range(0, 10):\n",
        "  pos_ind = np.where(testy==1)[0]\n",
        "  n = int(i/10 * len(pos_ind))\n",
        "  tmp_testX, tmp_testy = np.copy(testX), np.copy(testy)\n",
        "  tmp_testX = np.delete(tmp_testX, pos_ind[:n], axis=0)\n",
        "  tmp_testy = np.delete(tmp_testy, pos_ind[:n], axis=0)\n",
        "  print('nth %d:positive: %d negative: %d'\n",
        "        % (i, tmp_testy.sum(), tmp_testy.shape[0] - tmp_testy.sum()))\n",
        "  print('---------------------------------------------')\n",
        "\n",
        "  # predict probabilities\n",
        "  lr_probs = model.predict_proba(tmp_testX)\n",
        "  # keep probabilities for the positive outcome only\n",
        "  lr_probs = lr_probs[:, 1]\n",
        "  # calculate scores\n",
        "  lr_auc = roc_auc_score(tmp_testy, lr_probs)\n",
        "\n",
        "  # summarize scores\n",
        "  # print('iteration %d: Logistic: ROC AUC=%.3f' % (k, lr_auc))\n",
        "  k += 1\n",
        "  # calculate roc curves\n",
        "  lr_fpr, lr_tpr, _ = roc_curve(tmp_testy, lr_probs)\n",
        "  roc_list.append(lr_auc)\n",
        "\n",
        "plt.plot(np.arange(0, len(roc_list)), roc_list)\n",
        "plt.xlabel('skewness ratio')\n",
        "plt.ylabel('AUROC')\n",
        "plt.title('decreasing positive sample')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3wBwClARN0"
      },
      "source": [
        "## 질문 1: 데이터 불균형이 심해지는데 AUROC 평가 지표는 왜 높게 형성이 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UVEkuvKApcL"
      },
      "source": [
        "## 답변 1\n",
        "보고서 링크: https://hyeonchan.notion.site/29fe91a35de980b3adf1dc5cf7d91669?pvs=73\n",
        "\n",
        "\n",
        "**AUROC는 TPR과 FPR라는 지표를 사용하기 때문이다.**\n",
        "\n",
        "1. **혼동 행렬 (Confusion Matrix)**\n",
        "\n",
        "먼저 TPR과 FPR에 대해 알아보기 전에 혼동 행렬에 대해 알아보자.\n",
        "\n",
        "\n",
        "TP: 실제 Positive를 Positive로 올바르게 예측\n",
        "\n",
        "FN: 실제 Positive를 Negative로 틀리게 예측\n",
        "\n",
        "FP: 실제 Negative를 Positive로 틀리게 예측\n",
        "\n",
        "TN: 실제 Negative를 Negative로 올바르게 예측\n",
        "\n",
        "1. **TPR (True Positive Rate)**\n",
        "\n",
        "TPR이란 모델이 실제 Positive를 얼마나 올바르게 예측하는지 평가하는 지표이다. (=Recall)\n",
        "\n",
        "**실제 Positive인 샘플 중에서 모델이 Positive라고 올바르게 예측한 비율**을 의미한다.\n",
        "\n",
        "$TPR=\\frac{TP}{TP+FN}$ \n",
        "\n",
        "1. **FPR (False Positive Rate)**\n",
        "\n",
        "FPR이란 모델이 얼마나 잘못된 예측을 하는지 평가하는 지표이다.\n",
        "\n",
        "**실제 Negative인 샘플 중에서 모델이 Positive라고 잘못 예측한 비율**을 의미한다.\n",
        "\n",
        "$FPR=\\frac{FP}{FP+TN}$\n",
        "\n",
        "1. **임계값과 TPR/FPR의 관계**\n",
        "\n",
        "위 내용을 종합해보면, TPR이 높고 FPR이 낮을수록 모델의 성능이 좋아진다.\n",
        "\n",
        "모델의 Positive와 Negative를 결정하는 기준을 임계값(Threshold)이라 하는데, 이 값을 조절해보면 FPR과 TPR은 **트레이드 오프 관계**라는 걸 알 수 있다.\n",
        "\n",
        "만약 임계값을 낮추면 (Positive의 비율을 높이면) 더 많은 실제 Positive를 잡아낼 수 있다 (TPR 증가). \n",
        "\n",
        "하지만 Negative를 Positive로 잘못 판단하는 경우도 늘어난다 (FPR 증가). \n",
        "\n",
        "결과적으로 True Positive와 False Positive가 동시에 증가한다.\n",
        "\n",
        "반대로 임계값을 높이면 (Positive의 비율을 낮추면) Negative를 잘못 판단하는 실수가 줄어든다 (FPR 감소).\n",
        "\n",
        "하지만 그만큼 실제 Positive도 놓치게 된다 (TPR 감소).\n",
        "\n",
        "결과적으로 True Positive와 False Positive가 동시에 감소한다.\n",
        "\n",
        "1. **ROC 곡선과 AUROC**\n",
        "\n",
        "ROC 곡선은 모델의 임계값을 0부터 1까지 변경하면서, 모든 임계값 지점에서 계산되는 **FPR과 TPR의 관계**를 그린 그래프이다.\n",
        "\n",
        "\n",
        "- X축 (FPR): 0~1 (잘못된 예측의 비율)\n",
        "- Y축 (TPR): 0~1 (정확한 예측의 비율)\n",
        "\n",
        "AUROC는 ROC 곡선 아래의 면적을 계산한 값으로, 0.5~1 사이의 값을 가진다.\n",
        "\n",
        "AUROC는 임의로 선택된 Positive 샘플의 예측 확률이 Negative 샘플보다 높을 확률이다.\n",
        "\n",
        "즉, **모델이 두 클래스를 얼마나 잘 분리하는지를 나타내는 지표**다.\n",
        "\n",
        "1. **결론**\n",
        "\n",
        "AUROC는 TPR과 FPR의 관계를 이용해 그린 ROC 곡선에서 얻어내는 지표이다.\n",
        "\n",
        "그리고 이 두 지표는 각 클래스(Positive, Negative) **내부의 비율에 기반**하므로, 불균형에 상대적으로 덜 민감하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FRR3C2fhLkA"
      },
      "source": [
        "# 실습 2 : Precision, Recall, F1 Score의 이해\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0q7pb53rb6IK"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "0jfOJD8ccDTP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainy - class0:  253\n",
            "trainy - class1:  247\n",
            "----------------------\n",
            "testy - class0:  249\n",
            "testy - class1:  251\n",
            "============================\n",
            "Balanced Testing date\n",
            "testy - class0:  249\n",
            "testy - class1:  249\n"
          ]
        }
      ],
      "source": [
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=1000)\n",
        "\n",
        "print('trainy - class0: ', len(trainy)-trainy.sum())\n",
        "print('trainy - class1: ', trainy.sum())\n",
        "print('----------------------')\n",
        "print('testy - class0: ', len(testy)-testy.sum())\n",
        "print('testy - class1: ', testy.sum())\n",
        "print('============================')\n",
        "\n",
        "# make testing dataset balance\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "testX, testy = undersample.fit_resample(testX, testy)\n",
        "\n",
        "print('Balanced Testing date')\n",
        "print('testy - class0: ', len(testy)-testy.sum())\n",
        "print('testy - class1: ', testy.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FearSFM3cHJ6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-7 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-7 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-7 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content {\n",
              "  display: none;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  overflow: visible;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-7 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-7 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-7 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-7 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-7 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".estimator-table summary {\n",
              "    padding: .5rem;\n",
              "    font-family: monospace;\n",
              "    cursor: pointer;\n",
              "}\n",
              "\n",
              ".estimator-table details[open] {\n",
              "    padding-left: 0.1rem;\n",
              "    padding-right: 0.1rem;\n",
              "    padding-bottom: 0.3rem;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table {\n",
              "    margin-left: auto !important;\n",
              "    margin-right: auto !important;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(odd) {\n",
              "    background-color: #fff;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(even) {\n",
              "    background-color: #f6f6f6;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:hover {\n",
              "    background-color: #e0e0e0;\n",
              "}\n",
              "\n",
              ".estimator-table table td {\n",
              "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
              "}\n",
              "\n",
              ".user-set td {\n",
              "    color:rgb(255, 94, 0);\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td.value pre {\n",
              "    color:rgb(255, 94, 0) !important;\n",
              "    background-color: transparent !important;\n",
              "}\n",
              "\n",
              ".default td {\n",
              "    color: black;\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td i,\n",
              ".default td i {\n",
              "    color: black;\n",
              "}\n",
              "\n",
              ".copy-paste-icon {\n",
              "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
              "    background-repeat: no-repeat;\n",
              "    background-size: 14px 14px;\n",
              "    background-position: 0;\n",
              "    display: inline-block;\n",
              "    width: 14px;\n",
              "    height: 14px;\n",
              "    cursor: pointer;\n",
              "}\n",
              "</style><body><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
              "        <div class=\"estimator-table\">\n",
              "            <details>\n",
              "                <summary>Parameters</summary>\n",
              "                <table class=\"parameters-table\">\n",
              "                  <tbody>\n",
              "                    \n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('penalty',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">penalty&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('dual',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">dual&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('tol',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">tol&nbsp;</td>\n",
              "            <td class=\"value\">0.0001</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('C',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">C&nbsp;</td>\n",
              "            <td class=\"value\">1.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('fit_intercept',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('intercept_scaling',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
              "            <td class=\"value\">1</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('class_weight',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">class_weight&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('random_state',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">random_state&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('solver',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">solver&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('max_iter',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">max_iter&nbsp;</td>\n",
              "            <td class=\"value\">100</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('multi_class',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">multi_class&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('verbose',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">verbose&nbsp;</td>\n",
              "            <td class=\"value\">0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('warm_start',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">warm_start&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('n_jobs',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">n_jobs&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('l1_ratio',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "                  </tbody>\n",
              "                </table>\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "</script></body>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "SGece4JCcJF0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nth 0:positive: 249 negative: 249\n",
            "---------------------------------------------\n",
            "nth 1:positive: 225 negative: 249\n",
            "---------------------------------------------\n",
            "nth 2:positive: 200 negative: 249\n",
            "---------------------------------------------\n",
            "nth 3:positive: 175 negative: 249\n",
            "---------------------------------------------\n",
            "nth 4:positive: 150 negative: 249\n",
            "---------------------------------------------\n",
            "nth 5:positive: 125 negative: 249\n",
            "---------------------------------------------\n",
            "nth 6:positive: 100 negative: 249\n",
            "---------------------------------------------\n",
            "nth 7:positive: 75 negative: 249\n",
            "---------------------------------------------\n",
            "nth 8:positive: 50 negative: 249\n",
            "---------------------------------------------\n",
            "nth 9:positive: 25 negative: 249\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'decreasing positive sample')"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "roc_list = []\n",
        "f1_list = []\n",
        "\n",
        "k=1\n",
        "for i in range(0, 10):\n",
        "  pos_ind = np.where(testy==1)[0]\n",
        "  n = int(i/10 * len(pos_ind))\n",
        "  tmp_testX, tmp_testy = np.copy(testX), np.copy(testy)\n",
        "  tmp_testX = np.delete(tmp_testX, pos_ind[:n], axis=0)\n",
        "  tmp_testy = np.delete(tmp_testy, pos_ind[:n], axis=0)\n",
        "  print('nth %d:positive: %d negative: %d'\n",
        "        % (i, tmp_testy.sum(), tmp_testy.shape[0] - tmp_testy.sum()))\n",
        "  print('---------------------------------------------')\n",
        "\n",
        "\n",
        "  # predict probabilities\n",
        "  lr_probs = model.predict_proba(tmp_testX)\n",
        "  # keep probabilities for the positive outcome only\n",
        "  lr_probs = lr_probs[:, 1]\n",
        "  # predict class values\n",
        "  yhat = model.predict(tmp_testX)\n",
        "  # calculate precision and recall for each threshold\n",
        "  lr_precision, lr_recall, _ = precision_recall_curve(tmp_testy, lr_probs)\n",
        "  # calculate scores\n",
        "  lr_f1, lr_auc = f1_score(tmp_testy, yhat), auc(lr_recall, lr_precision)\n",
        "  # summarize scores\n",
        "  # print('iteration%d Logistic: f1=%.3f auc=%.3f' % (k, lr_f1, lr_auc))\n",
        "  k += 1\n",
        "  roc_list.append(lr_auc)\n",
        "  f1_list.append(lr_f1)\n",
        "\n",
        "plt.plot(np.arange(0, len(roc_list)), roc_list)\n",
        "plt.xlabel('skewness ratio')\n",
        "plt.ylabel('AUC of PR curve')\n",
        "plt.title('decreasing positive sample')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, len(roc_list)), f1_list)\n",
        "plt.xlabel('skewness ratio')\n",
        "plt.ylabel('F1')\n",
        "plt.title('decreasing positive sample')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oifr_1zhBdpo"
      },
      "source": [
        "## 질문 2: AUC, RC Curve와 F1 Curve는 데이터 불균형에 강건한 평가지표인가요? 강건하다면 AUROC보다  강건한 이유를, 그렇지 않다면 강건하지 않은 이유를 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkdtmhSByQL"
      },
      "source": [
        "## 답변 2\n",
        "1. **PR Curve (Precision-Recall Curve)**\n",
        "\n",
        "Precision-Recall Curve는 **Precision과 Recall의 관계를 시각화한 곡선**이다.\n",
        "\n",
        "- Precision: 모델이 예측한 샘플 중 실제 Positive의 비율 (모델의 예측이 얼마나 정확한지)\n",
        "    \n",
        "    $Precision=\\frac{TP}{TP+FP}$ \n",
        "    \n",
        "- Recall: 모델이 Positive로 올바르게 예측한 비율 (실제 Positive를 얼마나 놓치지 않았는지)\n",
        "    \n",
        "    $Recall=\\frac{TP}{FN+TP}$\n",
        "    \n",
        "\n",
        "PR Curve는 임계값을 0~1까지 변경해가며 X축에 Recall, Y축에 Precision을 표시한 그래프이다.\n",
        "\n",
        "1. **F1 Curve**\n",
        "\n",
        "F1 Curve는 **Precision과 Recall의 조화평균으로 나타낸 곡선**이다.\n",
        "\n",
        "$F1= 2 \\times \\frac{Precision\\times Recall}{Precision+Recall}$\n",
        "\n",
        "그렇기에 Precision과 Recall의 지표가 모두 높을 때 1에 가깝게 나온다.\n",
        "\n",
        "Precision이나 Recall 중 하나라도 낮으면, F1 Score는 크게 감소한다.\n",
        "\n",
        "따라서 F1 Curve는 모델의 임계값에 따라 Precision과 Recall이 어떻게 균형을 이루는지를 보여주는 지표이다.\n",
        "\n",
        "1. **PR Curve와 F1 Curve의 데이터 불균형에 대한 강건성**\n",
        "\n",
        "강건하다의 의미를 두 가지로 나누어 살펴볼 필요가 있다.\n",
        "\n",
        "1. **불균형에 영향을 덜 받음**\n",
        "    - 오히려 AUROC가 불균형에 영향을 덜 받는 지표이다. AUROC는 TPR과 FPR을 사용하며, 두 지표 모두 클래스 내부 비율을 기준으로 계산된다. 따라서 클래스 비율이 변하더라도 큰 왜곡이 발생하지 않는다.\n",
        "    - 반면 PR Curve와 F1 Score는 Precision을 사용한다. Precision의 분모는 TP + FP이기에 Negative 클래스의 개수에 직접적 영향을 받는다. 즉 **Negative가 많아질수록 FP가 상대적으로 늘어나 데이터 불균형에 민감**하다.\n",
        "2. **불균형 데이터를 잘 반영함**\n",
        "    - AUROC는 FPR의 분모에 TN이 포함되어 있어, Negative가 압도적으로 많을 경우 FP가 늘어나도 FPR이 미세하게만 증가한다. 따라서 **불균형 상황에서는 AUROC 값이 좋게 보이는 착시가 발생**한다. 즉, 모델이 실제 Positive를 거의 찾지 못해도 AUROC는 높게 유지될 수 있다.\n",
        "    - PR Curve와 F1-Score는 Positive 클래스의 탐지 성능에 집중한다. Precision과 Recall 모두 TN(실제 Negative)과 무관하게, Positive 관련 예측만 고려한다. 따라서 불균형 상황에서도 모델이 실제 Positive를 얼마나 잘 찾고 있는지를 정확하게 반영한다.\n",
        "\n",
        "결론적으로, **AUROC는 불균형 비율 변화에 안정적**이지만 Positive 탐지 성능을 과대평가할 수 있다.\n",
        "\n",
        "**PR Curve / F1-Score는 불균형에는 민감**하지만, Positive 중심 평가로 불균형 상황에 더 적합하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-mrND2BPc0"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHaJFnrsjsGJ"
      },
      "source": [
        "# 실습 3 : Convex Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "XhOZXU_ujyr7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At lamda 0.020, it is concave\n",
            "lhs -6.65710 rhs -7.84437\n",
            "At lamda 0.040, it is concave\n",
            "lhs -5.61247 rhs -7.84755\n",
            "At lamda 0.060, it is concave\n",
            "lhs -4.69589 rhs -7.85072\n",
            "At lamda 0.080, it is concave\n",
            "lhs -3.89644 rhs -7.85390\n",
            "At lamda 0.100, it is concave\n",
            "lhs -3.20369 rhs -7.85708\n",
            "At lamda 0.120, it is concave\n",
            "lhs -2.60770 rhs -7.86025\n",
            "At lamda 0.140, it is concave\n",
            "lhs -2.09901 rhs -7.86343\n",
            "At lamda 0.160, it is concave\n",
            "lhs -1.66864 rhs -7.86660\n",
            "At lamda 0.180, it is concave\n",
            "lhs -1.30811 rhs -7.86978\n",
            "At lamda 0.200, it is concave\n",
            "lhs -1.00943 rhs -7.87296\n",
            "At lamda 0.220, it is concave\n",
            "lhs -0.76507 rhs -7.87613\n",
            "At lamda 0.240, it is concave\n",
            "lhs -0.56802 rhs -7.87931\n",
            "At lamda 0.260, it is concave\n",
            "lhs -0.41173 rhs -7.88249\n",
            "At lamda 0.280, it is concave\n",
            "lhs -0.29015 rhs -7.88566\n",
            "At lamda 0.300, it is concave\n",
            "lhs -0.19773 rhs -7.88884\n",
            "At lamda 0.320, it is concave\n",
            "lhs -0.12936 rhs -7.89201\n",
            "At lamda 0.340, it is concave\n",
            "lhs -0.08048 rhs -7.89519\n",
            "At lamda 0.360, it is concave\n",
            "lhs -0.04696 rhs -7.89837\n",
            "At lamda 0.380, it is concave\n",
            "lhs -0.02520 rhs -7.90154\n",
            "At lamda 0.400, it is concave\n",
            "lhs -0.01205 rhs -7.90472\n",
            "At lamda 0.420, it is concave\n",
            "lhs -0.00487 rhs -7.90789\n",
            "At lamda 0.440, it is concave\n",
            "lhs -0.00151 rhs -7.91107\n",
            "At lamda 0.460, it is concave\n",
            "lhs -0.00029 rhs -7.91425\n",
            "At lamda 0.480, it is concave\n",
            "lhs -0.00002 rhs -7.91742\n",
            "At lamda 0.500, it is concave\n",
            "lhs -0.00000 rhs -7.92060\n",
            "At lamda 0.520, it is concave\n",
            "lhs -0.00003 rhs -7.92377\n",
            "At lamda 0.540, it is concave\n",
            "lhs -0.00037 rhs -7.92695\n",
            "At lamda 0.560, it is concave\n",
            "lhs -0.00178 rhs -7.93013\n",
            "At lamda 0.580, it is concave\n",
            "lhs -0.00552 rhs -7.93330\n",
            "At lamda 0.600, it is concave\n",
            "lhs -0.01332 rhs -7.93648\n",
            "At lamda 0.620, it is concave\n",
            "lhs -0.02739 rhs -7.93965\n",
            "At lamda 0.640, it is concave\n",
            "lhs -0.05045 rhs -7.94283\n",
            "At lamda 0.660, it is concave\n",
            "lhs -0.08568 rhs -7.94601\n",
            "At lamda 0.680, it is concave\n",
            "lhs -0.13677 rhs -7.94918\n",
            "At lamda 0.700, it is concave\n",
            "lhs -0.20789 rhs -7.95236\n",
            "At lamda 0.720, it is concave\n",
            "lhs -0.30368 rhs -7.95553\n",
            "At lamda 0.740, it is concave\n",
            "lhs -0.42929 rhs -7.95871\n",
            "At lamda 0.760, it is concave\n",
            "lhs -0.59035 rhs -7.96189\n",
            "At lamda 0.780, it is concave\n",
            "lhs -0.79296 rhs -7.96506\n",
            "At lamda 0.800, it is concave\n",
            "lhs -1.04373 rhs -7.96824\n",
            "At lamda 0.820, it is concave\n",
            "lhs -1.34974 rhs -7.97142\n",
            "At lamda 0.840, it is concave\n",
            "lhs -1.71857 rhs -7.97459\n",
            "At lamda 0.860, it is concave\n",
            "lhs -2.15828 rhs -7.97777\n",
            "At lamda 0.880, it is concave\n",
            "lhs -2.67741 rhs -7.98094\n",
            "At lamda 0.900, it is concave\n",
            "lhs -3.28500 rhs -7.98412\n",
            "At lamda 0.920, it is concave\n",
            "lhs -3.99056 rhs -7.98730\n",
            "At lamda 0.940, it is concave\n",
            "lhs -4.80411 rhs -7.99047\n",
            "At lamda 0.960, it is concave\n",
            "lhs -5.73613 rhs -7.99365\n",
            "At lamda 0.980, it is concave\n",
            "lhs -6.79760 rhs -7.99682\n"
          ]
        }
      ],
      "source": [
        "x = np.arange(-2, 2, 0.01)\n",
        "\n",
        "# 세 개의 함수 중 하나를 선택해서 돌려보세요\n",
        "# f = lambda x: 0.5 * x ** 2\n",
        "# f = lambda x: np.cos(np.pi * x)\n",
        "f = lambda x: -0.5 * x ** 4\n",
        "\n",
        "filenames=[]\n",
        "for lamda in np.arange(0, 1, 0.02):\n",
        "  # LHS\n",
        "  tmp_x = lamda*x[0] + (1-lamda)*x[-1]\n",
        "\n",
        "  # RHS\n",
        "  x_line, y_line = np.array([x[0], x[-1]]), np.array([lamda*f(x[0]), (1-lamda)*f(x[-1])])\n",
        "\n",
        "  # compute LHS and RHS\n",
        "  LHS = f(tmp_x)\n",
        "  RHS = lamda*f(x[0]) + (1-lamda)*f(x[-1])\n",
        "  if LHS > RHS:\n",
        "    print('At lamda %0.3f, it is concave' % lamda)\n",
        "    print('lhs %.5f rhs %.5f' % (LHS, RHS))\n",
        "\n",
        "  plt.figure()\n",
        "  # original graph\n",
        "  plt.plot(x, f(x), label='f(x)')\n",
        "  # plot RHS\n",
        "  plt.plot(x_line, y_line, label='%0.3f' % lamda)\n",
        "  # plot LHS\n",
        "  plt.scatter(tmp_x, f(tmp_x))\n",
        "  #title, legennd\n",
        "  plt.title('lhs %.3f rhs %.3f' % (LHS, RHS))\n",
        "  plt.legend()\n",
        "  plt.savefig('lamda %0.3f.png' % lamda)\n",
        "  plt.close()\n",
        "  filenames.append('lamda %0.3f.png' % lamda)\n",
        "\n",
        "# Build GIF\n",
        "with imageio.get_writer('mygif2.gif', mode='I') as writer:\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Y13zrWCbG8"
      },
      "source": [
        "## 질문 3-1: 3개의 함수를 확인할 수 있습니다. 3개의 함수중 최적화가 쉬운 함수는 무엇이고, 왜 그 함수가 최적화하기 쉬울까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K1QJkNJC4Qg"
      },
      "source": [
        "## 답변 3-1:\n",
        "1. **코드 실행**\n",
        "\n",
        "```python\n",
        "f = lambda x: 0.5 * x ** 2          # 1) Convex\n",
        "# f = lambda x: np.cos(np.pi * x)   # 2) 다중 최적해\n",
        "# f = lambda x: -0.5 * x ** 4       # 3) Concave\n",
        "```\n",
        "\n",
        "1. **두 번째 함수**\n",
        "\n",
        "두 번째 함수는 **여러 개의 지역 최적해**가 존재한다.\n",
        "\n",
        "여러 개의 지역 최적해가 존재한다는 것은 기울기가 0이 되는 지점이 여러 개 존재한다는 것이다.\n",
        "\n",
        "한 번 특정 지역 최적점에 도달하면 더 낮은 전역 최적점으로 이동할 수 없다.\n",
        "\n",
        "**즉, 전역 최적해로의 수렴이 보장되지 않으며 초기값에 따라 완전히 다른 해에 수렴**할 수 있다.\n",
        "\n",
        "\n",
        "1. **세 번째 함수**\n",
        "\n",
        "세 번째 함수는 Concave 함수이다.\n",
        "\n",
        "최적화는 일반적으로 **함수의 최소값을 찾는 문제**로 정의되며, 값을 작게 만드는 방향으로 이동한다.\n",
        "\n",
        "그러나 오목 함수는 최대값을 갖는 형태이므로, 기울기를 따라 내려가면 전역 최댓값이 아니라 **경계로 향하거나 발산**하게 된다.\n",
        "\n",
        "\n",
        "1. **첫 번째 함수**\n",
        "\n",
        "첫 번째 함수는 **Convex 함수**이다.\n",
        "\n",
        "**기울기가 0이 되는 지점이 단 하나만 존재**하기에 **지역 최적해와 전역 최적해가 항상 일치**한다.\n",
        "\n",
        "어떤 초기값에서도 안정적으로 전역 최적해에 도달할 수 있다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i3sCqKSCvzh"
      },
      "source": [
        "## 질문 3-2: 지역 최적해(local minimum)'와 '전역 최적해(global minimum)'의 차이점과 연관 지어, Non-convex 함수를 최적화할 때 발생할 수 있는 문제점은 무엇인지 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF8wCpR1C7kQ"
      },
      "source": [
        "## 답변 3-2:\n",
        "1. 지역 최적해와 전역 최적해\n",
        "- 지역 최적해: 함수의 특정 구간에서만 가장 작은 값을 갖는 지점\n",
        "- 전역 최적해: 함수 전체 영역에서 가장 작은 값을 갖는 지점\n",
        "\n",
        "즉 **지역 최적해는 부분적으로 낮은 지점이고 전역 최적해는 전체에서 가장 낮은 지점**이다.\n",
        "\n",
        "\n",
        "2. Non-convex 함수의 특성\n",
        "\n",
        "Non-convex 함수는 곡선이 여러 번 굴곡지기에 **여러 개의 지역 최적해**를 가진다.\n",
        "\n",
        "즉 **기울기가 0이 되는 지점이 여러 개 존재**한다.\n",
        "\n",
        "\n",
        "3. Non-convex 함수의 최적화 시 문제점\n",
        "\n",
        "1. **지역 최적해에 수렴**\n",
        "    - 여러 개의 지역 최적해가 존재하면 전역 최소점이 아닌 지역 최소점에 머물기에 전역 해에 도달하지 못할 수 있다.\n",
        "2. **초기값에 따른 민감도**\n",
        "    - 시작점에 따라 다른 지역 최소로 이동하기에 초기값에 따라 결과가 달라진다.\n",
        "3. **전역 최적해 보장 불가**\n",
        "    - Convex 함수는 지역 최적해가 곧 전역 최적해이지만 Non-convex 함수에서는 그렇지 않다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BInS8n0MqhHd"
      },
      "source": [
        "# 실습 4 : SGD Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define batch_size before using it in make_batch function\n",
        "batch_size = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "PR8SSeRPqwlb"
      },
      "outputs": [],
      "source": [
        "def make_data():\n",
        "    x1 = random.randint(0, 1)\n",
        "    x2 = random.randint(0, 1)\n",
        "    yy = 0 if (x1 == x2) else 1\n",
        "\n",
        "    # centered at zero\n",
        "    x1 = 2. * (x1 - 0.5)\n",
        "    x2 = 2. * (x2 - 0.5)\n",
        "    yy = 2. * (yy - 0.5)\n",
        "\n",
        "    # add noise\n",
        "    x1 += 0.1 * random.random()\n",
        "    x2 += 0.1 * random.random()\n",
        "    yy += 0.1 * random.random()\n",
        "\n",
        "    return [x1, x2, ], yy\n",
        "\n",
        "def make_batch():\n",
        "    data = [make_data() for ii in range(batch_size)]\n",
        "    labels = [label for xx, label in data]\n",
        "    data = [xx for xx, label in data]\n",
        "    return np.array(data, dtype='float32'), np.array(labels, dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "6f_GRAv4rLqf"
      },
      "outputs": [],
      "source": [
        "train_data = [make_batch() for ii in range(500)]\n",
        "test_data = [make_batch() for ii in range(50)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "usvcT9jbrRuv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iwc-fDtYrVd8"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "\n",
        "        self.dense1 = nn.Linear(2, 2)\n",
        "        self.dense2 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.tanh(self.dense1(x))\n",
        "        x = self.dense2(x)\n",
        "        return torch.squeeze(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "lohBBjxlrYUh"
      },
      "outputs": [],
      "source": [
        "# initialize our network\n",
        "model = NN()\n",
        "\n",
        "## optimizer = stochastic gradient descent\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "\n",
        "## train and test functions\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_data):\n",
        "        data, target = Variable(torch.from_numpy(data)), Variable(torch.from_numpy(target))\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.mse_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} {}\\tLoss: {:.4f}'.format(epoch, batch_idx * len(data), loss.item()))\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_data:\n",
        "        data, target = Variable(torch.from_numpy(data), volatile=True), Variable(torch.from_numpy(target))\n",
        "        output = model(data)\n",
        "        test_loss += F.mse_loss(output, target)\n",
        "        correct += (np.around(output.data.numpy()) == np.around(target.data.numpy())).sum()\n",
        "\n",
        "    test_loss /= len(test_data)\n",
        "    test_loss = test_loss.item()\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, batch_size * len(test_data), 100. * correct / (batch_size * len(test_data))) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "0q_oi1jfrtxy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr= 0.1\n",
            "Train Epoch: 1 0\tLoss: 1.2287\n",
            "Train Epoch: 1 3200\tLoss: 0.0448\n",
            "Train Epoch: 1 6400\tLoss: 0.0011\n",
            "Train Epoch: 1 9600\tLoss: 0.0012\n",
            "Train Epoch: 1 12800\tLoss: 0.0012\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 2 0\tLoss: 0.0006\n",
            "Train Epoch: 2 3200\tLoss: 0.0011\n",
            "Train Epoch: 2 6400\tLoss: 0.0011\n",
            "Train Epoch: 2 9600\tLoss: 0.0012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hye0nchan\\AppData\\Local\\Temp\\ipykernel_23208\\3879544526.py:26: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data, target = Variable(torch.from_numpy(data), volatile=True), Variable(torch.from_numpy(target))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 2 12800\tLoss: 0.0012\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 3 0\tLoss: 0.0006\n",
            "Train Epoch: 3 3200\tLoss: 0.0011\n",
            "Train Epoch: 3 6400\tLoss: 0.0011\n",
            "Train Epoch: 3 9600\tLoss: 0.0012\n",
            "Train Epoch: 3 12800\tLoss: 0.0012\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 4 0\tLoss: 0.0006\n",
            "Train Epoch: 4 3200\tLoss: 0.0010\n",
            "Train Epoch: 4 6400\tLoss: 0.0011\n",
            "Train Epoch: 4 9600\tLoss: 0.0011\n",
            "Train Epoch: 4 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 5 0\tLoss: 0.0006\n",
            "Train Epoch: 5 3200\tLoss: 0.0010\n",
            "Train Epoch: 5 6400\tLoss: 0.0011\n",
            "Train Epoch: 5 9600\tLoss: 0.0011\n",
            "Train Epoch: 5 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 6 0\tLoss: 0.0006\n",
            "Train Epoch: 6 3200\tLoss: 0.0010\n",
            "Train Epoch: 6 6400\tLoss: 0.0011\n",
            "Train Epoch: 6 9600\tLoss: 0.0011\n",
            "Train Epoch: 6 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 7 0\tLoss: 0.0006\n",
            "Train Epoch: 7 3200\tLoss: 0.0010\n",
            "Train Epoch: 7 6400\tLoss: 0.0011\n",
            "Train Epoch: 7 9600\tLoss: 0.0011\n",
            "Train Epoch: 7 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 8 0\tLoss: 0.0006\n",
            "Train Epoch: 8 3200\tLoss: 0.0010\n",
            "Train Epoch: 8 6400\tLoss: 0.0011\n",
            "Train Epoch: 8 9600\tLoss: 0.0011\n",
            "Train Epoch: 8 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 9 0\tLoss: 0.0006\n",
            "Train Epoch: 9 3200\tLoss: 0.0010\n",
            "Train Epoch: 9 6400\tLoss: 0.0011\n",
            "Train Epoch: 9 9600\tLoss: 0.0010\n",
            "Train Epoch: 9 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 10 0\tLoss: 0.0006\n",
            "Train Epoch: 10 3200\tLoss: 0.0010\n",
            "Train Epoch: 10 6400\tLoss: 0.0011\n",
            "Train Epoch: 10 9600\tLoss: 0.0010\n",
            "Train Epoch: 10 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 11 0\tLoss: 0.0007\n",
            "Train Epoch: 11 3200\tLoss: 0.0010\n",
            "Train Epoch: 11 6400\tLoss: 0.0011\n",
            "Train Epoch: 11 9600\tLoss: 0.0010\n",
            "Train Epoch: 11 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 12 0\tLoss: 0.0007\n",
            "Train Epoch: 12 3200\tLoss: 0.0010\n",
            "Train Epoch: 12 6400\tLoss: 0.0011\n",
            "Train Epoch: 12 9600\tLoss: 0.0010\n",
            "Train Epoch: 12 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 13 0\tLoss: 0.0007\n",
            "Train Epoch: 13 3200\tLoss: 0.0010\n",
            "Train Epoch: 13 6400\tLoss: 0.0011\n",
            "Train Epoch: 13 9600\tLoss: 0.0010\n",
            "Train Epoch: 13 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 14 0\tLoss: 0.0007\n",
            "Train Epoch: 14 3200\tLoss: 0.0010\n",
            "Train Epoch: 14 6400\tLoss: 0.0011\n",
            "Train Epoch: 14 9600\tLoss: 0.0010\n",
            "Train Epoch: 14 12800\tLoss: 0.0011\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 15 0\tLoss: 0.0007\n",
            "Train Epoch: 15 3200\tLoss: 0.0010\n",
            "Train Epoch: 15 6400\tLoss: 0.0011\n",
            "Train Epoch: 15 9600\tLoss: 0.0010\n",
            "Train Epoch: 15 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 16 0\tLoss: 0.0007\n",
            "Train Epoch: 16 3200\tLoss: 0.0010\n",
            "Train Epoch: 16 6400\tLoss: 0.0011\n",
            "Train Epoch: 16 9600\tLoss: 0.0010\n",
            "Train Epoch: 16 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 17 0\tLoss: 0.0007\n",
            "Train Epoch: 17 3200\tLoss: 0.0010\n",
            "Train Epoch: 17 6400\tLoss: 0.0011\n",
            "Train Epoch: 17 9600\tLoss: 0.0010\n",
            "Train Epoch: 17 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 18 0\tLoss: 0.0007\n",
            "Train Epoch: 18 3200\tLoss: 0.0010\n",
            "Train Epoch: 18 6400\tLoss: 0.0010\n",
            "Train Epoch: 18 9600\tLoss: 0.0010\n",
            "Train Epoch: 18 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 19 0\tLoss: 0.0007\n",
            "Train Epoch: 19 3200\tLoss: 0.0010\n",
            "Train Epoch: 19 6400\tLoss: 0.0010\n",
            "Train Epoch: 19 9600\tLoss: 0.0010\n",
            "Train Epoch: 19 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 20 0\tLoss: 0.0007\n",
            "Train Epoch: 20 3200\tLoss: 0.0010\n",
            "Train Epoch: 20 6400\tLoss: 0.0010\n",
            "Train Epoch: 20 9600\tLoss: 0.0010\n",
            "Train Epoch: 20 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 21 0\tLoss: 0.0007\n",
            "Train Epoch: 21 3200\tLoss: 0.0010\n",
            "Train Epoch: 21 6400\tLoss: 0.0010\n",
            "Train Epoch: 21 9600\tLoss: 0.0010\n",
            "Train Epoch: 21 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 22 0\tLoss: 0.0007\n",
            "Train Epoch: 22 3200\tLoss: 0.0010\n",
            "Train Epoch: 22 6400\tLoss: 0.0010\n",
            "Train Epoch: 22 9600\tLoss: 0.0010\n",
            "Train Epoch: 22 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 23 0\tLoss: 0.0007\n",
            "Train Epoch: 23 3200\tLoss: 0.0010\n",
            "Train Epoch: 23 6400\tLoss: 0.0010\n",
            "Train Epoch: 23 9600\tLoss: 0.0010\n",
            "Train Epoch: 23 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 24 0\tLoss: 0.0007\n",
            "Train Epoch: 24 3200\tLoss: 0.0009\n",
            "Train Epoch: 24 6400\tLoss: 0.0010\n",
            "Train Epoch: 24 9600\tLoss: 0.0010\n",
            "Train Epoch: 24 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 25 0\tLoss: 0.0007\n",
            "Train Epoch: 25 3200\tLoss: 0.0009\n",
            "Train Epoch: 25 6400\tLoss: 0.0010\n",
            "Train Epoch: 25 9600\tLoss: 0.0009\n",
            "Train Epoch: 25 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 26 0\tLoss: 0.0007\n",
            "Train Epoch: 26 3200\tLoss: 0.0009\n",
            "Train Epoch: 26 6400\tLoss: 0.0010\n",
            "Train Epoch: 26 9600\tLoss: 0.0009\n",
            "Train Epoch: 26 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 27 0\tLoss: 0.0007\n",
            "Train Epoch: 27 3200\tLoss: 0.0009\n",
            "Train Epoch: 27 6400\tLoss: 0.0010\n",
            "Train Epoch: 27 9600\tLoss: 0.0009\n",
            "Train Epoch: 27 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 28 0\tLoss: 0.0007\n",
            "Train Epoch: 28 3200\tLoss: 0.0009\n",
            "Train Epoch: 28 6400\tLoss: 0.0010\n",
            "Train Epoch: 28 9600\tLoss: 0.0009\n",
            "Train Epoch: 28 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 29 0\tLoss: 0.0007\n",
            "Train Epoch: 29 3200\tLoss: 0.0009\n",
            "Train Epoch: 29 6400\tLoss: 0.0010\n",
            "Train Epoch: 29 9600\tLoss: 0.0009\n",
            "Train Epoch: 29 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 30 0\tLoss: 0.0007\n",
            "Train Epoch: 30 3200\tLoss: 0.0009\n",
            "Train Epoch: 30 6400\tLoss: 0.0010\n",
            "Train Epoch: 30 9600\tLoss: 0.0009\n",
            "Train Epoch: 30 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 31 0\tLoss: 0.0007\n",
            "Train Epoch: 31 3200\tLoss: 0.0009\n",
            "Train Epoch: 31 6400\tLoss: 0.0010\n",
            "Train Epoch: 31 9600\tLoss: 0.0009\n",
            "Train Epoch: 31 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 32 0\tLoss: 0.0007\n",
            "Train Epoch: 32 3200\tLoss: 0.0009\n",
            "Train Epoch: 32 6400\tLoss: 0.0010\n",
            "Train Epoch: 32 9600\tLoss: 0.0009\n",
            "Train Epoch: 32 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 33 0\tLoss: 0.0007\n",
            "Train Epoch: 33 3200\tLoss: 0.0009\n",
            "Train Epoch: 33 6400\tLoss: 0.0010\n",
            "Train Epoch: 33 9600\tLoss: 0.0009\n",
            "Train Epoch: 33 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 34 0\tLoss: 0.0007\n",
            "Train Epoch: 34 3200\tLoss: 0.0009\n",
            "Train Epoch: 34 6400\tLoss: 0.0010\n",
            "Train Epoch: 34 9600\tLoss: 0.0009\n",
            "Train Epoch: 34 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 35 0\tLoss: 0.0007\n",
            "Train Epoch: 35 3200\tLoss: 0.0009\n",
            "Train Epoch: 35 6400\tLoss: 0.0010\n",
            "Train Epoch: 35 9600\tLoss: 0.0009\n",
            "Train Epoch: 35 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 36 0\tLoss: 0.0007\n",
            "Train Epoch: 36 3200\tLoss: 0.0009\n",
            "Train Epoch: 36 6400\tLoss: 0.0010\n",
            "Train Epoch: 36 9600\tLoss: 0.0009\n",
            "Train Epoch: 36 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 37 0\tLoss: 0.0007\n",
            "Train Epoch: 37 3200\tLoss: 0.0009\n",
            "Train Epoch: 37 6400\tLoss: 0.0010\n",
            "Train Epoch: 37 9600\tLoss: 0.0009\n",
            "Train Epoch: 37 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 38 0\tLoss: 0.0007\n",
            "Train Epoch: 38 3200\tLoss: 0.0009\n",
            "Train Epoch: 38 6400\tLoss: 0.0010\n",
            "Train Epoch: 38 9600\tLoss: 0.0009\n",
            "Train Epoch: 38 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 39 0\tLoss: 0.0007\n",
            "Train Epoch: 39 3200\tLoss: 0.0009\n",
            "Train Epoch: 39 6400\tLoss: 0.0010\n",
            "Train Epoch: 39 9600\tLoss: 0.0009\n",
            "Train Epoch: 39 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 40 0\tLoss: 0.0007\n",
            "Train Epoch: 40 3200\tLoss: 0.0009\n",
            "Train Epoch: 40 6400\tLoss: 0.0010\n",
            "Train Epoch: 40 9600\tLoss: 0.0009\n",
            "Train Epoch: 40 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 41 0\tLoss: 0.0007\n",
            "Train Epoch: 41 3200\tLoss: 0.0009\n",
            "Train Epoch: 41 6400\tLoss: 0.0010\n",
            "Train Epoch: 41 9600\tLoss: 0.0009\n",
            "Train Epoch: 41 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 42 0\tLoss: 0.0007\n",
            "Train Epoch: 42 3200\tLoss: 0.0009\n",
            "Train Epoch: 42 6400\tLoss: 0.0010\n",
            "Train Epoch: 42 9600\tLoss: 0.0009\n",
            "Train Epoch: 42 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 43 0\tLoss: 0.0007\n",
            "Train Epoch: 43 3200\tLoss: 0.0009\n",
            "Train Epoch: 43 6400\tLoss: 0.0010\n",
            "Train Epoch: 43 9600\tLoss: 0.0009\n",
            "Train Epoch: 43 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 44 0\tLoss: 0.0007\n",
            "Train Epoch: 44 3200\tLoss: 0.0009\n",
            "Train Epoch: 44 6400\tLoss: 0.0010\n",
            "Train Epoch: 44 9600\tLoss: 0.0009\n",
            "Train Epoch: 44 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 45 0\tLoss: 0.0007\n",
            "Train Epoch: 45 3200\tLoss: 0.0009\n",
            "Train Epoch: 45 6400\tLoss: 0.0010\n",
            "Train Epoch: 45 9600\tLoss: 0.0009\n",
            "Train Epoch: 45 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 46 0\tLoss: 0.0007\n",
            "Train Epoch: 46 3200\tLoss: 0.0009\n",
            "Train Epoch: 46 6400\tLoss: 0.0010\n",
            "Train Epoch: 46 9600\tLoss: 0.0009\n",
            "Train Epoch: 46 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 47 0\tLoss: 0.0007\n",
            "Train Epoch: 47 3200\tLoss: 0.0009\n",
            "Train Epoch: 47 6400\tLoss: 0.0010\n",
            "Train Epoch: 47 9600\tLoss: 0.0009\n",
            "Train Epoch: 47 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 48 0\tLoss: 0.0007\n",
            "Train Epoch: 48 3200\tLoss: 0.0009\n",
            "Train Epoch: 48 6400\tLoss: 0.0010\n",
            "Train Epoch: 48 9600\tLoss: 0.0009\n",
            "Train Epoch: 48 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 49 0\tLoss: 0.0007\n",
            "Train Epoch: 49 3200\tLoss: 0.0009\n",
            "Train Epoch: 49 6400\tLoss: 0.0010\n",
            "Train Epoch: 49 9600\tLoss: 0.0009\n",
            "Train Epoch: 49 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 50 0\tLoss: 0.0007\n",
            "Train Epoch: 50 3200\tLoss: 0.0009\n",
            "Train Epoch: 50 6400\tLoss: 0.0010\n",
            "Train Epoch: 50 9600\tLoss: 0.0009\n",
            "Train Epoch: 50 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 51 0\tLoss: 0.0007\n",
            "Train Epoch: 51 3200\tLoss: 0.0009\n",
            "Train Epoch: 51 6400\tLoss: 0.0010\n",
            "Train Epoch: 51 9600\tLoss: 0.0009\n",
            "Train Epoch: 51 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 52 0\tLoss: 0.0007\n",
            "Train Epoch: 52 3200\tLoss: 0.0009\n",
            "Train Epoch: 52 6400\tLoss: 0.0010\n",
            "Train Epoch: 52 9600\tLoss: 0.0009\n",
            "Train Epoch: 52 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 53 0\tLoss: 0.0007\n",
            "Train Epoch: 53 3200\tLoss: 0.0009\n",
            "Train Epoch: 53 6400\tLoss: 0.0010\n",
            "Train Epoch: 53 9600\tLoss: 0.0009\n",
            "Train Epoch: 53 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 54 0\tLoss: 0.0007\n",
            "Train Epoch: 54 3200\tLoss: 0.0009\n",
            "Train Epoch: 54 6400\tLoss: 0.0010\n",
            "Train Epoch: 54 9600\tLoss: 0.0009\n",
            "Train Epoch: 54 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 55 0\tLoss: 0.0007\n",
            "Train Epoch: 55 3200\tLoss: 0.0009\n",
            "Train Epoch: 55 6400\tLoss: 0.0010\n",
            "Train Epoch: 55 9600\tLoss: 0.0009\n",
            "Train Epoch: 55 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 56 0\tLoss: 0.0007\n",
            "Train Epoch: 56 3200\tLoss: 0.0009\n",
            "Train Epoch: 56 6400\tLoss: 0.0010\n",
            "Train Epoch: 56 9600\tLoss: 0.0009\n",
            "Train Epoch: 56 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 57 0\tLoss: 0.0007\n",
            "Train Epoch: 57 3200\tLoss: 0.0009\n",
            "Train Epoch: 57 6400\tLoss: 0.0010\n",
            "Train Epoch: 57 9600\tLoss: 0.0009\n",
            "Train Epoch: 57 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 58 0\tLoss: 0.0007\n",
            "Train Epoch: 58 3200\tLoss: 0.0009\n",
            "Train Epoch: 58 6400\tLoss: 0.0010\n",
            "Train Epoch: 58 9600\tLoss: 0.0009\n",
            "Train Epoch: 58 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 59 0\tLoss: 0.0007\n",
            "Train Epoch: 59 3200\tLoss: 0.0009\n",
            "Train Epoch: 59 6400\tLoss: 0.0010\n",
            "Train Epoch: 59 9600\tLoss: 0.0009\n",
            "Train Epoch: 59 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 60 0\tLoss: 0.0007\n",
            "Train Epoch: 60 3200\tLoss: 0.0009\n",
            "Train Epoch: 60 6400\tLoss: 0.0010\n",
            "Train Epoch: 60 9600\tLoss: 0.0009\n",
            "Train Epoch: 60 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 61 0\tLoss: 0.0007\n",
            "Train Epoch: 61 3200\tLoss: 0.0009\n",
            "Train Epoch: 61 6400\tLoss: 0.0010\n",
            "Train Epoch: 61 9600\tLoss: 0.0009\n",
            "Train Epoch: 61 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 62 0\tLoss: 0.0007\n",
            "Train Epoch: 62 3200\tLoss: 0.0009\n",
            "Train Epoch: 62 6400\tLoss: 0.0010\n",
            "Train Epoch: 62 9600\tLoss: 0.0009\n",
            "Train Epoch: 62 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 63 0\tLoss: 0.0007\n",
            "Train Epoch: 63 3200\tLoss: 0.0009\n",
            "Train Epoch: 63 6400\tLoss: 0.0010\n",
            "Train Epoch: 63 9600\tLoss: 0.0009\n",
            "Train Epoch: 63 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 64 0\tLoss: 0.0007\n",
            "Train Epoch: 64 3200\tLoss: 0.0009\n",
            "Train Epoch: 64 6400\tLoss: 0.0010\n",
            "Train Epoch: 64 9600\tLoss: 0.0009\n",
            "Train Epoch: 64 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 65 0\tLoss: 0.0007\n",
            "Train Epoch: 65 3200\tLoss: 0.0009\n",
            "Train Epoch: 65 6400\tLoss: 0.0010\n",
            "Train Epoch: 65 9600\tLoss: 0.0009\n",
            "Train Epoch: 65 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 66 0\tLoss: 0.0007\n",
            "Train Epoch: 66 3200\tLoss: 0.0009\n",
            "Train Epoch: 66 6400\tLoss: 0.0010\n",
            "Train Epoch: 66 9600\tLoss: 0.0009\n",
            "Train Epoch: 66 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 67 0\tLoss: 0.0007\n",
            "Train Epoch: 67 3200\tLoss: 0.0009\n",
            "Train Epoch: 67 6400\tLoss: 0.0010\n",
            "Train Epoch: 67 9600\tLoss: 0.0009\n",
            "Train Epoch: 67 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 68 0\tLoss: 0.0007\n",
            "Train Epoch: 68 3200\tLoss: 0.0009\n",
            "Train Epoch: 68 6400\tLoss: 0.0010\n",
            "Train Epoch: 68 9600\tLoss: 0.0009\n",
            "Train Epoch: 68 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 69 0\tLoss: 0.0007\n",
            "Train Epoch: 69 3200\tLoss: 0.0009\n",
            "Train Epoch: 69 6400\tLoss: 0.0010\n",
            "Train Epoch: 69 9600\tLoss: 0.0009\n",
            "Train Epoch: 69 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 70 0\tLoss: 0.0007\n",
            "Train Epoch: 70 3200\tLoss: 0.0009\n",
            "Train Epoch: 70 6400\tLoss: 0.0010\n",
            "Train Epoch: 70 9600\tLoss: 0.0009\n",
            "Train Epoch: 70 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 71 0\tLoss: 0.0007\n",
            "Train Epoch: 71 3200\tLoss: 0.0009\n",
            "Train Epoch: 71 6400\tLoss: 0.0010\n",
            "Train Epoch: 71 9600\tLoss: 0.0009\n",
            "Train Epoch: 71 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 72 0\tLoss: 0.0007\n",
            "Train Epoch: 72 3200\tLoss: 0.0009\n",
            "Train Epoch: 72 6400\tLoss: 0.0010\n",
            "Train Epoch: 72 9600\tLoss: 0.0009\n",
            "Train Epoch: 72 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 73 0\tLoss: 0.0007\n",
            "Train Epoch: 73 3200\tLoss: 0.0009\n",
            "Train Epoch: 73 6400\tLoss: 0.0010\n",
            "Train Epoch: 73 9600\tLoss: 0.0009\n",
            "Train Epoch: 73 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 74 0\tLoss: 0.0007\n",
            "Train Epoch: 74 3200\tLoss: 0.0009\n",
            "Train Epoch: 74 6400\tLoss: 0.0010\n",
            "Train Epoch: 74 9600\tLoss: 0.0009\n",
            "Train Epoch: 74 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 75 0\tLoss: 0.0007\n",
            "Train Epoch: 75 3200\tLoss: 0.0009\n",
            "Train Epoch: 75 6400\tLoss: 0.0010\n",
            "Train Epoch: 75 9600\tLoss: 0.0009\n",
            "Train Epoch: 75 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 76 0\tLoss: 0.0007\n",
            "Train Epoch: 76 3200\tLoss: 0.0009\n",
            "Train Epoch: 76 6400\tLoss: 0.0010\n",
            "Train Epoch: 76 9600\tLoss: 0.0009\n",
            "Train Epoch: 76 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 77 0\tLoss: 0.0007\n",
            "Train Epoch: 77 3200\tLoss: 0.0009\n",
            "Train Epoch: 77 6400\tLoss: 0.0010\n",
            "Train Epoch: 77 9600\tLoss: 0.0009\n",
            "Train Epoch: 77 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 78 0\tLoss: 0.0007\n",
            "Train Epoch: 78 3200\tLoss: 0.0009\n",
            "Train Epoch: 78 6400\tLoss: 0.0010\n",
            "Train Epoch: 78 9600\tLoss: 0.0009\n",
            "Train Epoch: 78 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 79 0\tLoss: 0.0007\n",
            "Train Epoch: 79 3200\tLoss: 0.0009\n",
            "Train Epoch: 79 6400\tLoss: 0.0010\n",
            "Train Epoch: 79 9600\tLoss: 0.0009\n",
            "Train Epoch: 79 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 80 0\tLoss: 0.0007\n",
            "Train Epoch: 80 3200\tLoss: 0.0009\n",
            "Train Epoch: 80 6400\tLoss: 0.0010\n",
            "Train Epoch: 80 9600\tLoss: 0.0009\n",
            "Train Epoch: 80 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 81 0\tLoss: 0.0007\n",
            "Train Epoch: 81 3200\tLoss: 0.0009\n",
            "Train Epoch: 81 6400\tLoss: 0.0010\n",
            "Train Epoch: 81 9600\tLoss: 0.0009\n",
            "Train Epoch: 81 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 82 0\tLoss: 0.0007\n",
            "Train Epoch: 82 3200\tLoss: 0.0009\n",
            "Train Epoch: 82 6400\tLoss: 0.0010\n",
            "Train Epoch: 82 9600\tLoss: 0.0009\n",
            "Train Epoch: 82 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 83 0\tLoss: 0.0007\n",
            "Train Epoch: 83 3200\tLoss: 0.0009\n",
            "Train Epoch: 83 6400\tLoss: 0.0010\n",
            "Train Epoch: 83 9600\tLoss: 0.0009\n",
            "Train Epoch: 83 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 84 0\tLoss: 0.0007\n",
            "Train Epoch: 84 3200\tLoss: 0.0009\n",
            "Train Epoch: 84 6400\tLoss: 0.0010\n",
            "Train Epoch: 84 9600\tLoss: 0.0009\n",
            "Train Epoch: 84 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 85 0\tLoss: 0.0007\n",
            "Train Epoch: 85 3200\tLoss: 0.0009\n",
            "Train Epoch: 85 6400\tLoss: 0.0010\n",
            "Train Epoch: 85 9600\tLoss: 0.0009\n",
            "Train Epoch: 85 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 86 0\tLoss: 0.0007\n",
            "Train Epoch: 86 3200\tLoss: 0.0009\n",
            "Train Epoch: 86 6400\tLoss: 0.0010\n",
            "Train Epoch: 86 9600\tLoss: 0.0009\n",
            "Train Epoch: 86 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 87 0\tLoss: 0.0007\n",
            "Train Epoch: 87 3200\tLoss: 0.0009\n",
            "Train Epoch: 87 6400\tLoss: 0.0010\n",
            "Train Epoch: 87 9600\tLoss: 0.0009\n",
            "Train Epoch: 87 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 88 0\tLoss: 0.0007\n",
            "Train Epoch: 88 3200\tLoss: 0.0009\n",
            "Train Epoch: 88 6400\tLoss: 0.0010\n",
            "Train Epoch: 88 9600\tLoss: 0.0009\n",
            "Train Epoch: 88 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 89 0\tLoss: 0.0007\n",
            "Train Epoch: 89 3200\tLoss: 0.0009\n",
            "Train Epoch: 89 6400\tLoss: 0.0010\n",
            "Train Epoch: 89 9600\tLoss: 0.0009\n",
            "Train Epoch: 89 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 90 0\tLoss: 0.0007\n",
            "Train Epoch: 90 3200\tLoss: 0.0009\n",
            "Train Epoch: 90 6400\tLoss: 0.0010\n",
            "Train Epoch: 90 9600\tLoss: 0.0009\n",
            "Train Epoch: 90 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 91 0\tLoss: 0.0007\n",
            "Train Epoch: 91 3200\tLoss: 0.0009\n",
            "Train Epoch: 91 6400\tLoss: 0.0010\n",
            "Train Epoch: 91 9600\tLoss: 0.0009\n",
            "Train Epoch: 91 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 92 0\tLoss: 0.0007\n",
            "Train Epoch: 92 3200\tLoss: 0.0009\n",
            "Train Epoch: 92 6400\tLoss: 0.0010\n",
            "Train Epoch: 92 9600\tLoss: 0.0009\n",
            "Train Epoch: 92 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 93 0\tLoss: 0.0007\n",
            "Train Epoch: 93 3200\tLoss: 0.0009\n",
            "Train Epoch: 93 6400\tLoss: 0.0010\n",
            "Train Epoch: 93 9600\tLoss: 0.0009\n",
            "Train Epoch: 93 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 94 0\tLoss: 0.0007\n",
            "Train Epoch: 94 3200\tLoss: 0.0009\n",
            "Train Epoch: 94 6400\tLoss: 0.0010\n",
            "Train Epoch: 94 9600\tLoss: 0.0009\n",
            "Train Epoch: 94 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 95 0\tLoss: 0.0007\n",
            "Train Epoch: 95 3200\tLoss: 0.0009\n",
            "Train Epoch: 95 6400\tLoss: 0.0010\n",
            "Train Epoch: 95 9600\tLoss: 0.0009\n",
            "Train Epoch: 95 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 96 0\tLoss: 0.0007\n",
            "Train Epoch: 96 3200\tLoss: 0.0009\n",
            "Train Epoch: 96 6400\tLoss: 0.0010\n",
            "Train Epoch: 96 9600\tLoss: 0.0009\n",
            "Train Epoch: 96 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 97 0\tLoss: 0.0007\n",
            "Train Epoch: 97 3200\tLoss: 0.0009\n",
            "Train Epoch: 97 6400\tLoss: 0.0010\n",
            "Train Epoch: 97 9600\tLoss: 0.0009\n",
            "Train Epoch: 97 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 98 0\tLoss: 0.0007\n",
            "Train Epoch: 98 3200\tLoss: 0.0009\n",
            "Train Epoch: 98 6400\tLoss: 0.0010\n",
            "Train Epoch: 98 9600\tLoss: 0.0009\n",
            "Train Epoch: 98 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 99 0\tLoss: 0.0007\n",
            "Train Epoch: 99 3200\tLoss: 0.0009\n",
            "Train Epoch: 99 6400\tLoss: 0.0010\n",
            "Train Epoch: 99 9600\tLoss: 0.0009\n",
            "Train Epoch: 99 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n",
            "Train Epoch: 100 0\tLoss: 0.0007\n",
            "Train Epoch: 100 3200\tLoss: 0.0009\n",
            "Train Epoch: 100 6400\tLoss: 0.0010\n",
            "Train Epoch: 100 9600\tLoss: 0.0009\n",
            "Train Epoch: 100 12800\tLoss: 0.0010\n",
            "---------------------------------------------\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 1600/1600 (100.00%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## run experiment\n",
        "nepochs = 100\n",
        "lr = 0.1\n",
        "\n",
        "print('lr=', lr)\n",
        "for epoch in range(1, nepochs + 1):\n",
        "    train(epoch)\n",
        "    print('---------------------------------------------')\n",
        "    test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TL-BeLji0nV"
      },
      "source": [
        "## 실습 4: lr값을 다음 4개의 값으로 돌려보고, 어떤 value가 왜 적절한지 설명해주세요. lr값을 다음 4개의 값으로 돌려보고, 어떤 value가 왜 적절한지 설명해주세요. lr = [0,0001, 0.001, 0.01, 0.1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL7gfBDri1bs"
      },
      "source": [
        "## 답변 4  \n",
        "1. 학습률 (Learning Rate)\n",
        "\n",
        "학습률은 경사하강법에서 가중치를 업데이트할 때 **이동하는 크기 (Step size)를 결정하는 하이퍼파라미터**이다. 너무 작으면 수렴이 늦어지고 너무 크면 발산하거나 진동할 수 있다.\n",
        "\n",
        "2. 실험 결과 및 분석\n",
        "\n",
        "1. LR = 0.0001\n",
        "    - 관찰: **손실이 천천히 감소**하며 일정 수준 이하로 잘 내려가지 않음\n",
        "    - 추정: step이 너무 작아 평탄 구간 / 지역해 근처에서 머뭄\n",
        "    \n",
        "    ```\n",
        "    Train Epoch: 1 0\tLoss: 1.4701\n",
        "    Train Epoch: 1 3200\tLoss: 1.2156\n",
        "    Train Epoch: 1 6400\tLoss: 1.4234\n",
        "    Train Epoch: 1 9600\tLoss: 1.2143\n",
        "    Train Epoch: 1 12800\tLoss: 1.2964\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    Train Epoch: 4 0\tLoss: 1.2505\n",
        "    Train Epoch: 4 3200\tLoss: 1.0541\n",
        "    Train Epoch: 4 6400\tLoss: 1.2116\n",
        "    Train Epoch: 4 9600\tLoss: 1.0897\n",
        "    Train Epoch: 4 12800\tLoss: 1.1411\n",
        "    ```\n",
        "    \n",
        "2. LR = 0.001\n",
        "    - 관찰: 0.0001 대비 개선되지만 여전히 완만한 하강, 낮은 구간으로의 진입이 더딤\n",
        "    - 추정: 여전히 step이 너무 작아 평탄 구간 / 지역해 근처에서 머뭄\n",
        "    \n",
        "    ```\n",
        "    Train Epoch: 1 0\tLoss: 1.0741\n",
        "    Train Epoch: 1 3200\tLoss: 1.1589\n",
        "    Train Epoch: 1 6400\tLoss: 0.9062\n",
        "    Train Epoch: 1 9600\tLoss: 1.1113\n",
        "    Train Epoch: 1 12800\tLoss: 1.0750\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    Train Epoch: 4 0\tLoss: 0.9590\n",
        "    Train Epoch: 4 3200\tLoss: 1.0053\n",
        "    Train Epoch: 4 6400\tLoss: 0.9372\n",
        "    Train Epoch: 4 9600\tLoss: 0.9744\n",
        "    ```\n",
        "    \n",
        "3. LR = 0.01\n",
        "    - 관찰: 초기부터 **손실값이 빠르고 안정적으로 감소**\n",
        "    - 추정: 속도와 안정성의 균형이 좋은 것으로 보아 적절해보임\n",
        "    \n",
        "    ```\n",
        "    Train Epoch: 1 0\tLoss: 1.3017\n",
        "    Train Epoch: 1 3200\tLoss: 1.0067\n",
        "    Train Epoch: 1 6400\tLoss: 0.9424\n",
        "    Train Epoch: 1 9600\tLoss: 0.8358\n",
        "    Train Epoch: 1 12800\tLoss: 0.6348\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    Train Epoch: 4 0\tLoss: 0.0008\n",
        "    Train Epoch: 4 3200\tLoss: 0.0008\n",
        "    Train Epoch: 4 6400\tLoss: 0.0008\n",
        "    Train Epoch: 4 9600\tLoss: 0.0013\n",
        "    Train Epoch: 4 12800\tLoss: 0.0014\n",
        "    ```\n",
        "    \n",
        "4. LR = 0.1\n",
        "    - 관찰: 손실값이 매우 가파르게 감소, 수렴하긴 했는데 **미세한 진동**이 있는 것 같아서 불안함\n",
        "    - 추정: 모델의 크기가 커지면 불안정성이 확대될 거 같음\n",
        "    \n",
        "    ```\n",
        "    Train Epoch: 1 0\tLoss: 0.9642\n",
        "    Train Epoch: 1 3200\tLoss: 0.0020\n",
        "    Train Epoch: 1 6400\tLoss: 0.0008\n",
        "    Train Epoch: 1 9600\tLoss: 0.0013\n",
        "    Train Epoch: 1 12800\tLoss: 0.0013\n",
        "    \n",
        "    ... \n",
        "    \n",
        "    Train Epoch: 4 0\tLoss: 0.0006\n",
        "    Train Epoch: 4 3200\tLoss: 0.0009\n",
        "    Train Epoch: 4 6400\tLoss: 0.0008\n",
        "    Train Epoch: 4 9600\tLoss: 0.0012\n",
        "    Train Epoch: 4 12800\tLoss: 0.0013\n",
        "    ```\n",
        "    \n",
        "\n",
        "1. **비교**\n",
        "\n",
        "| IR | 초기 하강 속도 | 최종 손실 | 평가 |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.0001 | 느림 | > 1.0  | 비효율 |\n",
        "| 0.001 | 보통 | ~1.0 전후  | 비효율 |\n",
        "| 0.01 | 빠름 | ~1e-3 | 적절 |\n",
        "| 0.1 | 매우 빠름 | ~1e-3 | 적절 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdfix_cK0DA8"
      },
      "source": [
        "# 실습 5: Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "PlF_9SSqruLJ"
      },
      "outputs": [],
      "source": [
        "f = lambda x, w, b: 1/(1 + np.exp(-(w*x + b)))\n",
        "\n",
        "x = np.arange(-10, 10, 0.01).reshape([-1, 1])\n",
        "\n",
        "# effect of weight on sigmoid function\n",
        "filenames = []\n",
        "for i in np.arange(1, 5, 0.1):\n",
        "  w = np.ones([1, 1]) * i * 0.5\n",
        "  b = np.ones([1, 1]) * 0\n",
        "\n",
        "  plt.plot(x, f(x, w, b))\n",
        "  plt.title('w = %0.1f' % i)\n",
        "  plt.grid()\n",
        "  plt.savefig('w %0.1f.png' % i)\n",
        "  plt.close()\n",
        "  filenames.append('w %0.1f.png' % i)\n",
        "\n",
        "# Build GIF\n",
        "with imageio.get_writer('w_mygif.gif', mode='I') as writer:\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "L5tEXHXB05bJ"
      },
      "outputs": [],
      "source": [
        "f = lambda x, w, b: 1/(1 + np.exp(-(w*x + b)))\n",
        "\n",
        "x = np.arange(-10, 10, 0.01).reshape([-1, 1])\n",
        "\n",
        "# effect of bias on sigmoid function\n",
        "filenames = []\n",
        "for i in np.arange(1, 5, 0.1):\n",
        "  w = np.ones([1, 1])\n",
        "  b = np.ones([1, 1])* i\n",
        "\n",
        "  plt.plot(x, f(x, w, b))\n",
        "  plt.title('b = %0.1f' % i)\n",
        "  plt.grid()\n",
        "  plt.savefig('b %0.1f.png' % i)\n",
        "  plt.close()\n",
        "  filenames.append('b %0.1f.png' % i)\n",
        "\n",
        "# Build GIF\n",
        "with imageio.get_writer('b_mygif.gif', mode='I') as writer:\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJCC-ny31Zm_"
      },
      "source": [
        "# 실습 6: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "h6weNkLv1VaV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "3VBXpIO21faZ"
      },
      "outputs": [],
      "source": [
        "input_size = 28 * 28  # 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "NjQic-8v1nMf"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "\n",
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "c3f5447c2kCw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ../../data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "----------------\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ../../data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "training data shape:  torch.Size([60000, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hye0nchan\\miniconda3\\envs\\ml_2025\\lib\\site-packages\\torchvision\\datasets\\mnist.py:66: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'n = 107 label = 3')"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2.3.1 Check data\n",
        "print(train_dataset)\n",
        "print('----------------')\n",
        "print(test_dataset)\n",
        "print()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print('training data shape: ', train_dataset.data.shape)\n",
        "n = np.random.randint(0, 60000)\n",
        "plt.imshow(train_dataset.data[n])\n",
        "plt.title(f'n = %d label = %d' % (n, train_dataset.train_labels[n].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "FWLJSzhO2ofy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 2.2012\n",
            "Epoch [1/5], Step [200/600], Loss: 2.1062\n",
            "Epoch [1/5], Step [300/600], Loss: 2.0059\n",
            "Epoch [1/5], Step [400/600], Loss: 1.9329\n",
            "Epoch [1/5], Step [500/600], Loss: 1.8637\n",
            "Epoch [1/5], Step [600/600], Loss: 1.7757\n",
            "Epoch [2/5], Step [100/600], Loss: 1.7562\n",
            "Epoch [2/5], Step [200/600], Loss: 1.6472\n",
            "Epoch [2/5], Step [300/600], Loss: 1.6535\n",
            "Epoch [2/5], Step [400/600], Loss: 1.5377\n",
            "Epoch [2/5], Step [500/600], Loss: 1.4737\n",
            "Epoch [2/5], Step [600/600], Loss: 1.4446\n",
            "Epoch [3/5], Step [100/600], Loss: 1.3987\n",
            "Epoch [3/5], Step [200/600], Loss: 1.4378\n",
            "Epoch [3/5], Step [300/600], Loss: 1.3605\n",
            "Epoch [3/5], Step [400/600], Loss: 1.3800\n",
            "Epoch [3/5], Step [500/600], Loss: 1.2996\n",
            "Epoch [3/5], Step [600/600], Loss: 1.2809\n",
            "Epoch [4/5], Step [100/600], Loss: 1.2575\n",
            "Epoch [4/5], Step [200/600], Loss: 1.2173\n",
            "Epoch [4/5], Step [300/600], Loss: 1.1297\n",
            "Epoch [4/5], Step [400/600], Loss: 1.1269\n",
            "Epoch [4/5], Step [500/600], Loss: 1.1469\n",
            "Epoch [4/5], Step [600/600], Loss: 1.0912\n",
            "Epoch [5/5], Step [100/600], Loss: 1.0711\n",
            "Epoch [5/5], Step [200/600], Loss: 1.0426\n",
            "Epoch [5/5], Step [300/600], Loss: 1.2128\n",
            "Epoch [5/5], Step [400/600], Loss: 1.1122\n",
            "Epoch [5/5], Step [500/600], Loss: 1.0755\n",
            "Epoch [5/5], Step [600/600], Loss: 1.1282\n"
          ]
        }
      ],
      "source": [
        "#2.4 Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "\n",
        "#2.5 Cross Entropy Loss\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#2.6 Optimizer Stochastic Gradient Descent\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#2.7 Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, input_size)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "H0qHxJfl20bF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 83.12000274658203 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, input_size)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YYOMWRpkxlz"
      },
      "source": [
        "## 코드 구현 6-1 : 아래 log_softmax함수를 구현하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "dvoS9aOv3K9y"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (3494579062.py, line 13)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[86], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    def log_softmax(x):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "class custom_CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(custom_CrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        num_examples = targets.shape[0]\n",
        "        batch_size = inputs.shape[0]\n",
        "        softmax_outputs = self.log_softmax(inputs)\n",
        "        outputs = softmax_outputs[range(batch_size), targets]\n",
        "        return -torch.sum(outputs)/num_examples\n",
        "\n",
        "    @staticmethod\n",
        "        def log_softmax(x):\n",
        "            x_max = torch.max(x, dim = 1, keepdim = True)[0]\n",
        "            x_shifted = x - x_max\n",
        "            return x_shifted - torch.log(torch.sum(torch.exp(x_shifted), dim = 1, keepdim =True ))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o8zodMzk9RH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 2.2172\n",
            "Epoch [1/5], Step [200/600], Loss: 2.1365\n",
            "Epoch [1/5], Step [300/600], Loss: 2.0821\n",
            "Epoch [1/5], Step [400/600], Loss: 1.9401\n",
            "Epoch [1/5], Step [500/600], Loss: 1.8756\n",
            "Epoch [1/5], Step [600/600], Loss: 1.7805\n",
            "Epoch [2/5], Step [100/600], Loss: 1.7204\n",
            "Epoch [2/5], Step [200/600], Loss: 1.6520\n",
            "Epoch [2/5], Step [300/600], Loss: 1.5849\n",
            "Epoch [2/5], Step [400/600], Loss: 1.5461\n",
            "Epoch [2/5], Step [500/600], Loss: 1.4994\n",
            "Epoch [2/5], Step [600/600], Loss: 1.3967\n",
            "Epoch [3/5], Step [100/600], Loss: 1.3905\n",
            "Epoch [3/5], Step [200/600], Loss: 1.3352\n",
            "Epoch [3/5], Step [300/600], Loss: 1.3418\n",
            "Epoch [3/5], Step [400/600], Loss: 1.3789\n",
            "Epoch [3/5], Step [500/600], Loss: 1.2761\n",
            "Epoch [3/5], Step [600/600], Loss: 1.2311\n",
            "Epoch [4/5], Step [100/600], Loss: 1.2660\n",
            "Epoch [4/5], Step [200/600], Loss: 1.2898\n",
            "Epoch [4/5], Step [300/600], Loss: 1.1391\n",
            "Epoch [4/5], Step [400/600], Loss: 1.1485\n",
            "Epoch [4/5], Step [500/600], Loss: 1.0872\n",
            "Epoch [4/5], Step [600/600], Loss: 1.1066\n",
            "Epoch [5/5], Step [100/600], Loss: 1.0385\n",
            "Epoch [5/5], Step [200/600], Loss: 1.0026\n",
            "Epoch [5/5], Step [300/600], Loss: 0.9359\n",
            "Epoch [5/5], Step [400/600], Loss: 1.0463\n",
            "Epoch [5/5], Step [500/600], Loss: 0.9956\n",
            "Epoch [5/5], Step [600/600], Loss: 0.9866\n"
          ]
        }
      ],
      "source": [
        "#2.4 Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "\n",
        "#2.5 Cross Entropy Loss\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#2.6 Optimizer Stochastic Gradient Descent\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#2.7 Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, input_size)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtcBrioBlBIJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 83.06999969482422 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, input_size)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmMQHFT2lg7j"
      },
      "source": [
        "## 질문 6 : 다중 분류 문제에서는 왜 sigmoid를 사용하지 못하고 softmax를 사용하게 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2fGsOsn_Gf"
      },
      "source": [
        "## 답변 6\n",
        "\n",
        "\n",
        "1. **Sigmoid Function**\n",
        "\n",
        "시그모이드 함수는 **임의의 실수 입력(z)을 0과 1사이의 값으로 압축**한다.\n",
        "\n",
        "$\\alpha(z)=\\frac{1}{1+e^{-z}}$\n",
        "\n",
        "- 출력값은 0~1 사이이며, 입력이 커질수록 1에 가까워지고 작을수록 0에 가까워진다.\n",
        "- 주로 이진 분류에서 각 클래스의 존재 확률을 예측할 때 사용된다.\n",
        "- 각 출력 노드는 **서로 독립적으로 확률을 계산**한다.\n",
        "\n",
        "**2. Softmax Function**\n",
        "\n",
        "소프트맥스 함수는 K개의 클래스에 대한 벡터를 입력받아 K개 클래스에 대한 확률 분포를 출력한다.\n",
        "\n",
        "$\\alpha(z)_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{K}e^{z_{i}}}$\n",
        "\n",
        "- 각 출력값은 0~1 사이의 확률을 의미한다.\n",
        "- **모든 출력의 합은 항상 1이 되며 한 클래스의 확률은 다른 모든 클래스의 값에 영향**을 준다.\n",
        "\n",
        "**3. Sigmoid를 사용할 수 없는 이유**\n",
        "\n",
        "1. 확률의 총합이 1이 아님\n",
        "    \n",
        "    시그모이드는 각 출력을 독립적으로 계산한다.\n",
        "    \n",
        "    따라서 각 클래스별 확률이 높게 나올 수 있으며, 전체 확률의 합이 1이 되지 않는다.\n",
        "    \n",
        "    예를 들어, $P(1) = 0.8, \\space P(7) = 0.5$와 같이 **여러 클래스가 동시에 높은 확률**을 가질 수 있다.\n",
        "    \n",
        "    이 경우, 1.3 > 1로, 확률적 해석이 불가능하다.\n",
        "    \n",
        "2. 클래스 간 독립적 확률 계산\n",
        "    \n",
        "    또한 어떤 클래스의 확률이 높아져도 다른 클래스의 확률이 낮아지지 않는다.\n",
        "    \n",
        "    1일 확률이 높다 해서 7일 확률이 낮아지지 않는다. \n",
        "    \n",
        "    이는 클래스 간 경쟁 관계를 모델링하지 못한다.\n",
        "    \n",
        "\n",
        "**4 Sofmax를 사용해야 하는 이유**\n",
        "\n",
        "1. 확률 분포 생성\n",
        "    \n",
        "    **출력값들의 총합이 항상 1이 되도록 강제**한다. 이는 입력 데이터가 K개의 클래스 중 하나에 속할 **확률을 전체적인 분포로 보여준다**\n",
        "    \n",
        "2. 클래스 간 경쟁 모델링\n",
        "    \n",
        "    모든 출력이 같은 분모를 공유하므로, **한 클래스의 확률이 높아지면 다른 클래스의 확률이 자동으로 낮아진다.**\n",
        "    \n",
        "    특정 클래스일 확률 높아지면 다른 클래스의 확률은 상대적으로 낮아진다.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml_2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
